{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7cd66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf454d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>flower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   flower  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df['flower'] = iris.target\n",
    "# df['flower'] = df['flower'].apply(lambda x: iris.target_names[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59bdfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['flower'],axis=1), df['flower'],\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b4ee2",
   "metadata": {},
   "source": [
    "# Approach 1: Use train_test_split and manually tune parameters by trial and error\n",
    "\n",
    "So we have loaded Iris flower dataset, Now the traditional approach that we can take to solve this problem is we use Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019acea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595377e",
   "metadata": {},
   "source": [
    "And then lets say we first try the SVM model, so first we will see how to do HyperParameter tuning and then will look into how to choose the model so just assume that u are going to use SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49532d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf',C=30,gamma='auto')\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2d5e32",
   "metadata": {},
   "source": [
    "Above we randomly initialize with some parameters, since we dont know what is the best Parameters.\n",
    "\n",
    "The issue here is that base on your Train and Test set the score might vary, right now our score is 97% but if we exevute it again it will change so we cant rely on this mthod as the score keeps changing base on our sample, so for that reason we use K FOLD Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db184513",
   "metadata": {},
   "source": [
    "# Approach 2: Use K Fold Cross validationÂ¶\n",
    "Below what we will do is try cross_val_score for 5 folds and try this method on different values of \"Kernel\" and \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5bf75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svm.SVC(kernel='linear',C=10,gamma='auto'),iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21fb9186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.96666667, 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf',C=10,gamma='auto'),iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3823fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 1.        , 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm.SVC(kernel='rbf',C=20,gamma='auto'),iris.data, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be6745",
   "metadata": {},
   "source": [
    "You can see above we got 5 values for different parameters, u can find the average of these values and based on that you can determine the optimal value of these Parameters.\n",
    "\n",
    "But u can see that this method is very manual and repitative cuz there are so many values you can supply as different combinations so u will have to make alot of cross validation to try out different combinations.\n",
    "\n",
    "So the other approach we can take is we can just run a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d8d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rbf_1': 0.9800000000000001,\n",
       " 'rbf_10': 0.9800000000000001,\n",
       " 'rbf_20': 0.9666666666666668,\n",
       " 'linear_1': 0.9800000000000001,\n",
       " 'linear_10': 0.9733333333333334,\n",
       " 'linear_20': 0.9666666666666666}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "kernels = ['rbf', 'linear']\n",
    "C = [1,10,20]\n",
    "avg_scores = {}\n",
    "for kval in kernels:\n",
    "    for cval in C:\n",
    "        cv_scores = cross_val_score(svm.SVC(kernel=kval,C=cval,gamma='auto'),iris.data, iris.target, \n",
    "                                    cv=5),\n",
    "        avg_scores[kval + '_' + str(cval)] = np.average(cv_scores)\n",
    "\n",
    "avg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c54de",
   "metadata": {},
   "source": [
    "# Approach 3: Use GridSearchCV\n",
    "As above we can see using this way we can also find the best optimal score but u can see that this approach also has some issues like if we have 4 parameters then will have to run like 4 loops then it will be too many itertions and its just not convenient.\n",
    "\n",
    "Luckily SKLearn provides an API called GridSearchCV which will do the exact same thing, i will do the exact same thing as shown in the for loop above but we will be able to do that in a single line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1e5e5",
   "metadata": {},
   "source": [
    "Now the first parameter we pass in GridSearchCV is the model so for our example we use SVM and we apply gamma value to be auto, then the Second parameter is very important, this is your parameter grid, in parameter grid, u will say i want the value of \"C\" to be 1, 10 and 20, these are the different value that we are going to try, and then \"kernel\" and in kernel we want to try \"rbf\" and \"linear\".\n",
    "\n",
    "There are other parameters as well in GridSearchCV for example \"cv\" as third parameter to define how many Cross Validation u want to run, GridSearchSV uses cross validation, its just that we have the for loop step here in a line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8e36d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_kernel  mean_test_score  rank_test_score\n",
       "0        1          rbf         0.961905                3\n",
       "1        1       linear         0.980952                1\n",
       "2        1         poly         0.961905                3\n",
       "3       10          rbf         0.971429                2\n",
       "4       10       linear         0.961905                3\n",
       "5       10         poly         0.952381                8\n",
       "6       20          rbf         0.961905                3\n",
       "7       20       linear         0.961905                3\n",
       "8       20         poly         0.942857                9\n",
       "9       50          rbf         0.942857                9\n",
       "10      50       linear         0.942857                9\n",
       "11      50         poly         0.933333               12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(svm.SVC(gamma='auto'), \n",
    "                   {\n",
    "                       'kernel' : ['rbf', 'linear', 'poly'],\n",
    "                       'C':[1,10,20,50]\n",
    "                   }, cv=5, return_train_score=False)\n",
    "grid.fit(X_train, y_train)\n",
    "# View the GridSearchCV result in a nice DataFrame\n",
    "gridresult = pd.DataFrame(grid.cv_results_)\n",
    "# Show only important columns\n",
    "gridresult[['param_C','param_kernel','mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c85d29",
   "metadata": {},
   "source": [
    "And now u can have many many parameters, all u have to do is supply them in parameter grid inside GridSearchCV and it will take care of it and show u the scores in this nice dataframes\n",
    "\n",
    "We can do dir method in our clf to see what other properties it has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f02aa89a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_refit_for_multimetric',\n",
       " '_estimator_type',\n",
       " '_format_results',\n",
       " '_get_default_requests',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_required_parameters',\n",
       " '_run_search',\n",
       " '_select_best_index',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'best_estimator_',\n",
       " 'best_index_',\n",
       " 'best_params_',\n",
       " 'best_score_',\n",
       " 'classes_',\n",
       " 'cv',\n",
       " 'cv_results_',\n",
       " 'decision_function',\n",
       " 'error_score',\n",
       " 'estimator',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'inverse_transform',\n",
       " 'multimetric_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_splits_',\n",
       " 'param_grid',\n",
       " 'pre_dispatch',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'refit',\n",
       " 'refit_time_',\n",
       " 'return_train_score',\n",
       " 'score',\n",
       " 'score_samples',\n",
       " 'scorer_',\n",
       " 'scoring',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'transform',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1451678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, gamma='auto', kernel='linear')\n",
      "0.980952380952381\n",
      "{'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# dir(grid) to display all properties\n",
    "# of gridsearchcv\n",
    "dir(grid)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acba08",
   "metadata": {},
   "source": [
    "One issue that can happen with GridSearchCV is the Computation cost, our dataset now is very limited but imagine if u have millions of datapoints and then for parameters u have so many values, right now \"C\" values are only 1,10,20 but what if i just want to try range lets say from 1 to 50 then our Computation cost will go very high because this will literelly try Permutation and Combinations for every value of each of these parameters.\n",
    "\n",
    "To tackle this Computation problems, SKLearn libraries comes up with another class called RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40b30c",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV\n",
    "\n",
    "RandomizedSearchCV will not try every single Permutatuon and combination of parameters but it will try random combinations of these parameters value and u can chose what those iterations could be so lets see how it works.\n",
    "\n",
    "Lets say we want to try only 2 iterations, so we pass 2 in **'n_iter'** parameter, so it will just randomly try only 2 combination and you can go with whatever is best, this is useful when you have low computation power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ce6a439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C param_kernel  mean_test_score\n",
       "0       1       linear             0.98\n",
       "1       1          rbf             0.98"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(svm.SVC(gamma='auto'), {\n",
    "        'C': [1,10,20,30],\n",
    "        'kernel': ['rbf','linear','poly']\n",
    "    }, \n",
    "    cv=5, \n",
    "    return_train_score=False, \n",
    "    n_iter=2 # means try 2 random combo only\n",
    ")\n",
    "rs.fit(iris.data, iris.target) # train the data\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','param_kernel','mean_test_score']] # view as df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5ded8",
   "metadata": {},
   "source": [
    "As we can see above, it randomly tried C value and the kernel as well, if we run it again it will randomly change.\n",
    "\n",
    "This way it just randomly tries the value of C and kernel and it gives u the best score.\n",
    "\n",
    "This works well in a practical life cuz if u dont have too much computation power then u just want to try random value or parameters and just go with whatever comes out the best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5204d",
   "metadata": {},
   "source": [
    "# Choosing best Model\n",
    "### How about different models with different hyperparameters?\n",
    "Alright so now we looked into parameter tuning, now lets see how do we chose the best model. For our iris dataset we are going to try SVM, Random Forest and Logistic Regression and we will figure out which one will give u the best performant with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "662bb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto'),\n",
    "        'params' : {\n",
    "            'C': [1,10,20,30],\n",
    "            'kernel': ['rbf','linear','poly']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10],\n",
    "            'criterion' : ['gini', 'entropy']\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f9913",
   "metadata": {},
   "source": [
    "Once we have initialized this Dictionoary, we can write a simple for loop and this for loop is doing nothing but its just going through this Dictionary values and for each of the values it will GridSearchCV and in GridSearchCV the first param is the model, just trying each of the model from the Dictionary one by one with the corresponding parameters grid that we have specified in the above Dictionary.\n",
    "\n",
    "Then we run the Training and just append the scores into the scores list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79fbc365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                               best_params\n",
       "0                  svm    0.980952              {'C': 1, 'kernel': 'linear'}\n",
       "1        random_forest    0.942857  {'criterion': 'gini', 'n_estimators': 5}\n",
       "2  logistic_regression    0.952381                                  {'C': 1}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for model, mp in model_params.items():\n",
    "    grid = GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    grid.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model' : model,\n",
    "        'best_score': grid.best_score_,\n",
    "        'best_params': grid.best_params_\n",
    "    })\n",
    "# make a df\n",
    "resultdf = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "resultdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0985061a",
   "metadata": {},
   "source": [
    "As we can see above a nice table view of the model, best score and best parameters of each model, so here we have a Conclusion that best model for our dataset is SVM as it will give us a 98% score with C : 1 and kernel : \"linear\" parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3e7f3",
   "metadata": {},
   "source": [
    "So not only we did Hyperparameters tuning but we also selected the best model, above we have used only 3 models for demonstration but u can use 100 models if u like so this is more like Trial and Error approach but in Practical life this works really well and this is what is used to figure out the best model and the best parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
